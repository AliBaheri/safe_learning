{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import GPy\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from utilities import line_search_bisection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameter grid\n",
    "def combinations(arrays):\n",
    "    \"\"\"Return a single array with combinations of parameters\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arrays - list of np.array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    array - np.array\n",
    "        An array that contains all combinations of the input arrays\n",
    "    \"\"\"\n",
    "    return np.array(np.meshgrid(*arrays)).T.reshape(-1, len(arrays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lqr(A, B, Q, R):\n",
    "    \"\"\"\n",
    "    Compute the continuous time LQR-controller. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A - np.array\n",
    "    B - np.array\n",
    "    Q - np.array\n",
    "    R - np.array\n",
    "     \n",
    "    Returns\n",
    "    -------\n",
    "    K - np.array\n",
    "        Controller matrix\n",
    "    P - np.array\n",
    "        Cost to go matrix\n",
    "    \"\"\"\n",
    " \n",
    "    #first, try to solve the ricatti equation\n",
    "    P = sp.linalg.solve_continuous_are(A, B, Q, R)\n",
    "     \n",
    "    #compute the LQR gain\n",
    "    K = np.linalg.solve(R, B.T.dot(P))\n",
    "     \n",
    "    return K, P\n",
    "\n",
    "\n",
    "def quadratic_lyapunov_function(x, P):\n",
    "    \"\"\"\n",
    "    Compute V(x) for quadratic Lyapunov function\n",
    "    \n",
    "    V(x) = x.T P x\n",
    "    \n",
    "    Equivalent, but slower implementation:\n",
    "    np.array([ xi.dot(p.dot(xi.T)) for xi in x])\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x - np.array\n",
    "        2d array that has a vector x on each row\n",
    "    P - np.array\n",
    "        2d cost matrix for lyapunov function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    V - np.array\n",
    "        1d array with V(x)\n",
    "    dV - np.array\n",
    "        2d array with dV(x)/dx on each row\n",
    "    \"\"\"\n",
    "    return np.sum(x.dot(P) * x, axis=1), x.dot(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_V_dot(dV, mean, var=None, beta=2.):\n",
    "    \"\"\"\n",
    "    Compute the safe set\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dV - np.array\n",
    "        The derivatives of the Lyapunov function at grid points\n",
    "    mean - np.array\n",
    "        gp mean of the dynamics (including prior dynamics as mean)\n",
    "    var - np.array\n",
    "        gp var of the dynamics\n",
    "    beta - float\n",
    "        The confidence interval for the GP-prediction\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    V_dot - np.array\n",
    "        The beta-upper confidence bound on V_dot \n",
    "    \"\"\"    \n",
    "    # V_dot_mean = dV * mu\n",
    "    # V_dot_var = sum_i(|dV_i| * var_i)\n",
    "    # If output dimensions were correlated, the variance could be further reduced\n",
    "    # by considering correlations (predicting the sum term directly).\n",
    "    if var is None:\n",
    "        return np.sum(dV * mean, axis=1)\n",
    "    else:\n",
    "        return np.sum(dV * mean, axis=1) + beta * np.sqrt(np.sum(dV**2 * var, axis=1)) \n",
    "\n",
    "def get_safe_set(V_dot, threshold, S0=None):\n",
    "    \"\"\"\n",
    "    Compute the safe set\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    V_dot - np.array\n",
    "        V_dot at all grid points\n",
    "    threshold - float\n",
    "        The safety threshold, in the paper threshold = tau * L\n",
    "    S0 - np.array\n",
    "        The deterministic safe set\n",
    "    \"\"\"    \n",
    "    if S0 is None:\n",
    "        return V_dot < -threshold\n",
    "    else:\n",
    "        return np.logical_or(S0, V_dot < -threshold)\n",
    "        \n",
    "def find_max_levelset(S, V, accuracy, interval=None):\n",
    "    \"\"\"\n",
    "    Find maximum level set of V in S.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    S - boolean array\n",
    "        Elements are True if V_dot <= L tau\n",
    "    V - np.array\n",
    "        1d array with values of Lyapunov function.\n",
    "    accuracy - float\n",
    "        The accuracy up to which the level set is computed\n",
    "    interval - list\n",
    "        Interval within which the level set is search. Defaults\n",
    "        to [0, max(V) + accuracy]\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    c - float\n",
    "        The value of the maximum level set\n",
    "    \"\"\"\n",
    "    \n",
    "    def levelset_is_safe(c):\n",
    "        \"\"\"\n",
    "        Return true if V(c) is subset of S\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        c: float\n",
    "            The level set value\n",
    "            \n",
    "        Returns:\n",
    "        safe: boolean\n",
    "        \"\"\"\n",
    "        # All points that have V<=c should be safe (have S=True)\n",
    "        return np.all(S[V <= c])\n",
    "    \n",
    "    if interval is None:\n",
    "        interval = [0, np.max(V) + accuracy]\n",
    "    return line_search_bisection(levelset_is_safe,\n",
    "                                 interval,\n",
    "                                 accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tau = 0.005\n",
    "\n",
    "# x_min, x_max, accuracy\n",
    "grid_param = [(-math.radians(45), math.radians(45), tau),\n",
    "              (-2, 2, tau)]\n",
    "\n",
    "extent = np.array([grid_param[0][0], grid_param[0][1], grid_param[1][0], grid_param[1][1]])\n",
    "\n",
    "grid = [np.arange(*x) for x in grid_param]\n",
    "num_samples = [len(x) for x in grid]\n",
    "grid = combinations(grid)\n",
    "\n",
    "print('Grid size: {0}'.format(len(grid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 2\n",
    "m = 1\n",
    "\n",
    "mass = 0.1\n",
    "friction = 0.\n",
    "length = 0.5\n",
    "gravity = 9.81\n",
    "\n",
    "x_max = np.deg2rad(45)\n",
    "u_max = gravity * mass * length * np.sin(x_max)\n",
    "# u_max = np.deg2rad(45)\n",
    "# x_max = np.rad2deg(np.arcsin(u_max / (mass * gravity * length)))\n",
    "\n",
    "inertia = mass * length ** 2\n",
    "\n",
    "A = np.array([[0, 1],\n",
    "              [math.sqrt(gravity / length), -friction / inertia]])\n",
    "\n",
    "B = np.array([[0],\n",
    "              [1 / intertia]])\n",
    "\n",
    "Q = np.array([[1, 0], [0, 1]], dtype=np.float)\n",
    "R = np.array([[1]], dtype=np.float)\n",
    "\n",
    "# x_n = inv(Tx) * x\n",
    "Tx = np.diag([x_max, gravity / length * math.cos(x_max) * 0.1])\n",
    "Tu = np.array([[u_max]])\n",
    "\n",
    "Tx_inv = np.diag(np.diag(Tx)**(-1))\n",
    "Tu_inv = np.diag(np.diag(Tu)**(-1))\n",
    "\n",
    "Q = Tx_inv.T.dot(Q.dot(Tx_inv))\n",
    "R = Tu_inv.T.dot(R.dot(Tu_inv))\n",
    "\n",
    "Q *= np.array(1e-3, dtype=np.float)\n",
    "R *= np.array(1e-3, dtype=np.float)\n",
    "\n",
    "\n",
    "def ode(x, u):\n",
    "    return np.hstack([x[:, [1]],\n",
    "                      gravity / length * np.sin(x[:, [0]]) + u / inertia - friction / inertia * x[:, [1]]])\n",
    "\n",
    "K, P = lqr(A, B, Q, R)\n",
    "\n",
    "def control_law(x):\n",
    "    return -x.dot(K.T)\n",
    "\n",
    "def true_dynamics(x):\n",
    "    x = np.asarray(x)\n",
    "    u = control_law(x)\n",
    "    u = np.clip(u, -0.2, 0.2)\n",
    "    return ode(x, u)\n",
    "\n",
    "def prior_dynamics(x):\n",
    "    x = np.asarray(x)\n",
    "    u = control_law(x)\n",
    "    return x.dot(A.T) + u.dot(B.T)\n",
    "\n",
    "# Initial safe set\n",
    "S0 = np.logical_and(np.abs(grid[:, 0]) < np.deg2rad(5), True)\n",
    "\n",
    "if not np.any(S0):\n",
    "    print('No initial safe points!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.max(np.abs(prior_dynamics(grid) - true_dynamics(grid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel definition\n",
    "\n",
    "The inverted pendulum model is of the form\n",
    "\\begin{equation}\n",
    "\\ddot{\\theta} = \\frac{mgl \\sin(\\theta) + \\tau}{m l^2}\n",
    "\\end{equation}\n",
    "\n",
    "or, with the state vector $\\mathbf{x} = [\\mathbf{x}_1, \\mathbf{x}_2] = [\\theta, \\dot{\\theta}]$, the dynamics are\n",
    "\\begin{equation}\n",
    "\\dot{\\mathbf{x}} =\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "\\mathbf{x}_2 \\\\\n",
    "\\frac{mgl \\sin(\\mathbf{x}_1) + \\tau}{m l^2}\n",
    "\\end{matrix} \\right]\n",
    "\\end{equation}\n",
    "\n",
    "The first part of this equation says that the angle is equal to the integrated angular velocity. This is a intuitively true, irrespective of model errors. As such, we only train a model on the second part of the dynamics. That is\n",
    "\\begin{equation}\n",
    "\\dot{\\mathbf{x}} =\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "\\mathbf{x}_2 \\\\\n",
    "\\frac{mgl \\sin(\\mathbf{x}_1) + \\tau}{m l^2} + g_\\pi(\\mathbf{x})\n",
    "\\end{matrix} \\right]\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mf = GPy.core.Mapping(2, 1)\n",
    "mf.f = lambda x: prior_dynamics(x)[:, [1]]\n",
    "mf.update_gradients = lambda a,b: None\n",
    "\n",
    "kernel = GPy.kern.RBF(input_dim=2, lengthscale=0.5, variance=20**2, ARD=True)\n",
    "likelihood = GPy.likelihoods.Gaussian(variance=0.01**2)\n",
    "gp = GPy.core.GP(np.array([[0, 0]]), np.array([[0]]), kernel, likelihood, mean_function=mf)\n",
    "\n",
    "def predict_model(gp, x):\n",
    "    gp_mean, gp_var = gp._raw_predict(x)\n",
    "    gp_mean = np.hstack([x[:, [1]], gp_mean])\n",
    "    gp_var = np.hstack([np.zeros_like(gp_var), gp_var])\n",
    "    return gp_mean, gp_var\n",
    "L = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lipschitz constants of Lyapunov function\n",
    "L_dV = np.max(P)\n",
    "L_V = np.max(dV)\n",
    "\n",
    "\n",
    "kernel_lengthscale = np.min(gp.kern.lengthscale).squeeze().tolist()\n",
    "kernel_var = gp.kern.variance.values.squeeze().tolist()\n",
    "\n",
    "# Dynamics Lipschitz constants\n",
    "L_g = np.sqrt(kernel_var) / kernel_lengthscale\n",
    "L_f = max(np.max(A), np.max(B))\n",
    "\n",
    "# Function bounds\n",
    "B_g = np.sqrt(kernel_var)\n",
    "B_f = np.max(prior_dynamics(grid))\n",
    "\n",
    "B_true = np.max(true_dynamics(grid))\n",
    "\n",
    "L = (B_g + B_f) * L_V + L_dV * (L_g + L_f)\n",
    "L_true = B_true * L_V + L_dV * L_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(L, L_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True safe levelset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V, dV = quadratic_lyapunov_function(grid, P)\n",
    "V_max = np.max(V)\n",
    "accuracy = V_max / 1e10\n",
    "\n",
    "V_dot_true = np.sum(dV * true_dynamics(grid), axis=1)\n",
    "S = V_dot_true <= -L*tau\n",
    "if np.all(S):\n",
    "    print('All points safe')\n",
    "elif not np.any(S):\n",
    "    print('All points unsafe')\n",
    "\n",
    "c = find_max_levelset(np.logical_or(S, S0), V, accuracy)\n",
    "S[:] = V <= c\n",
    "plt.imshow(np.reshape(S, num_samples).T, extent=extent, origin='lower')\n",
    "plt.show()\n",
    "\n",
    "c = plt.imshow(np.reshape(V_dot_true, num_samples).T, extent=extent, origin='lower')\n",
    "plt.colorbar(c)\n",
    "plt.show()\n",
    "\n",
    "print('Number of safe points: {0}/{1}'.format(np.count_nonzero(S), grid.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V, dV = quadratic_lyapunov_function(grid, P)\n",
    "    \n",
    "def update_gp():\n",
    "    dynamics_mean, dynamics_var = predict_model(gp, grid)\n",
    "    if np.any(gp_var < 0):\n",
    "        print('negative variance Oo')\n",
    "    V_dot = compute_V_dot(dV, dynamics_mean, dynamics_var, beta=2.)\n",
    "    S = get_safe_set(V_dot, L*tau, S0=S0)\n",
    "    c = find_max_levelset(S, V, accuracy)\n",
    "    S[:] = V <= c\n",
    "    max_id = np.argmax(dynamics_var[S, 1])\n",
    "    max_state = grid[S][[max_id], :].copy()\n",
    "    gp.set_XY(np.vstack([gp.X, max_state]),\n",
    "              np.vstack([gp.Y, true_dynamics(max_state)[:, [1]]]))\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    update_gp()\n",
    "S = update_gp()\n",
    "print(np.count_nonzero(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "c = plt.imshow(np.reshape(S, num_samples).T, extent=extent, origin='lower')\n",
    "# c = plt.imshow(np.reshape(V_dot, num_samples).T < 0, extent=extent, origin='lower', cmap='viridis')\n",
    "# plt.colorbar(c)\n",
    "plt.plot(gp.X[:, 0], gp.X[:, 1], 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error = np.abs(true_dynamics(grid)[:, 1] - prior_dynamics(grid)[:, 1])\n",
    "c = plt.imshow(np.reshape(error, num_samples).T, extent=extent, origin='lower', cmap='viridis')\n",
    "plt.colorbar(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.min(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
