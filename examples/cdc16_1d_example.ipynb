{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import GPy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "%matplotlib inline\n",
    "\n",
    "# Try to import safe_rl from system\n",
    "# if it fails get it from the main folder directly instead.\n",
    "import utilities\n",
    "from plotting import plot_lyapunov_1d\n",
    "\n",
    "# If library not installed, import it from '../'\n",
    "safe_learning = utilities.import_from_directory('safe_learning', '../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining a discretization of the space $[-1, 1]$ with discretization constant $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Discretization constant\n",
    "tau = 0.001\n",
    "\n",
    "# x_min, x_max, discretization\n",
    "grid_param = [-1., 1., tau]\n",
    "extent = np.array(grid_param[:2])\n",
    "\n",
    "# Create a grid\n",
    "grid = np.arange(*grid_param)[:, None]\n",
    "num_samples = len(grid)\n",
    "\n",
    "print('Grid size: {0}'.format(len(grid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw system dynamics from a GP\n",
    "\n",
    "We define a kernel, $k(x,x') = k_{\\mathrm{linear}}(x, x') * k_{\\mathrm{Matern}}(x, x')$, which models a nonlinear, 2-times differentiable function with linearly increasing amplitude. We draw a sample from this kernel in order to define the dynamics.\n",
    "\n",
    "The following plot shows the kind of functions that this kernel implies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kernel = GPy.kern.Matern32(1, lengthscale=0.2, variance=0.2**2) * GPy.kern.Linear(1)\n",
    "\n",
    "for i in range(10):\n",
    "    f = safe_learning.sample_gp_function(\n",
    "        kernel,\n",
    "        [extent],\n",
    "        num_samples=100,\n",
    "        noise_var=0.1,\n",
    "        interpolation='kernel')\n",
    "    plt.plot(grid, f(grid, noise=False))\n",
    "\n",
    "plt.ylabel('$f(x)$')\n",
    "plt.xlabel('x')\n",
    "plt.title('Samples drawn from the GP model of the dynamics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the GP model using one particular sample of the GP, in addition to a stable, closed-loop, linear model.\n",
    "$$\\dot{x} = -0.25 x + g_\\pi(x),$$\n",
    "\n",
    "The prior dynamics are locally asymptotically stable. Moreover, in the one-dimensional case, the dynamics are stable as long as $\\dot{x} > 0$ if $x<0$ and $\\dot{x} < 0$ if $x>0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Observation noise\n",
    "noise_var = 0.01 ** 2\n",
    "\n",
    "# Mean dynamics\n",
    "mf = GPy.core.Mapping(1, 1)\n",
    "mf.f = lambda x: -0.25 * x\n",
    "mf.update_gradients = lambda a, b: None\n",
    "\n",
    "# Define one sample as the true dynamics\n",
    "np.random.seed(5)\n",
    "true_dynamics = safe_learning.sample_gp_function(\n",
    "    kernel,\n",
    "    [extent],\n",
    "    num_samples=100,\n",
    "    noise_var=noise_var,\n",
    "    interpolation='kernel',\n",
    "    mean_function=mf.f)\n",
    "\n",
    "# Define a GP model over the dynamics\n",
    "gp = GPy.models.GPRegression(np.array([[0]]),\n",
    "                             np.array([[0]]),\n",
    "                             kernel,\n",
    "                             noise_var=noise_var,\n",
    "                             mean_function=mf)\n",
    "\n",
    "# Plot the basic model\n",
    "gp.plot_f(plot_limits=extent)\n",
    "plt.plot(grid, true_dynamics(grid, noise=False), color='black', alpha=0.8)\n",
    "plt.title('GP model of the dynamics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally we define a random lyapunov function. Unlike for multiple dimensions, in the one-dimensional case all radially increasing functions are equivalent. Here we pick\n",
    "$$V(x) = x^2$$\n",
    "The previous GP model defines a GP model over $\\dot{V}(x) = \\frac{\\partial V(x)}{\\partial x} f(x)$. In the following, we only consider the 2-$\\sigma$ upper confidence bound of this model. Since the dynamics are Lipschitz continuous, $\\dot{V}$ is Lipschitz continuous as well.\n",
    "\n",
    "In particular, we use Lemma 5 to determine an appropriate Lipschitz constant. For the sample path of the GP, we use the high-probability Lipschitz constant encoded by the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyapunov_function = safe_learning.QuadraticFunction(np.array([[1]]))\n",
    "dynamics = safe_learning.GPyGaussianProcess(gp, beta=2.)\n",
    "lyapunov = safe_learning.LyapunovContinuous(grid, lyapunov_function, dynamics, tau, None)\n",
    "\n",
    "# Lipschitz constant\n",
    "L_dyn = 0.25 + dynamics.beta(0) * np.sqrt(gp.kern.Mat32.variance) / gp.kern.Mat32.lengthscale * np.max(np.abs(extent))\n",
    "B_dyn = (0.25 + np.sqrt(gp.kern.Mat32.variance)) * np.max(np.abs(extent))\n",
    "B_dV = L_V = np.max(lyapunov.dV)\n",
    "L_dV = 1\n",
    "\n",
    "lyapunov.lipschitz = safe_learning.LyapunovContinuous.lipschitz_constant(B_dyn, L_dyn, B_dV, L_dV)\n",
    "\n",
    "# Specify the desired accuracy\n",
    "accuracy = np.max(lyapunov.V) / 1e10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Safety based on GP model\n",
    "\n",
    "Let's start by plotting the prior over the dynamics and the associated prior over $\\dot{V}(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyapunov.update_safe_set(accuracy=accuracy)\n",
    "plot_lyapunov_1d(lyapunov, true_dynamics, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the model does not allow us to classify any states as safe ($\\dot{V} < -L \\tau$). However, as a starting point, we assume that we know that the system is asymptotially stable within some initial set, $\\mathcal{S}_0$:\n",
    "\n",
    "$$\\mathcal{S}_0 = \\{ x \\in \\mathbb{R} \\,|\\, |x| < 0.2 \\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyapunov.initial_safe_set = np.abs(lyapunov.discretization.squeeze()) < 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online learning\n",
    "As we sample within this initial safe set, we gain more knowledge about the system. In particular, we iteratively select the state withing the safe set, $\\mathcal{S}_n$, where the dynamics are the most uncertain (highest variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_gp():\n",
    "    \"\"\"Update the GP model based on an actively selected data point.\"\"\"\n",
    "    lyapunov.update_safe_set(accuracy=accuracy)\n",
    "    safe_set = lyapunov.safe_set\n",
    "    \n",
    "    # Maximum uncertainty in safe set\n",
    "    dynamics_mean, dynamics_std = lyapunov.dynamics.evaluate(grid)\n",
    "    max_id = np.argmax(dynamics_std[safe_set])\n",
    "    max_state = grid[safe_set][[max_id], :].copy()\n",
    "    \n",
    "    # Add newly obtained data point to the GP\n",
    "    measurement = true_dynamics(max_state, noise=True)[:, [0]]\n",
    "    lyapunov.dynamics.add_data_point(max_state, measurement)\n",
    "    return safe_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Update the GP model a couple of times\n",
    "for i in range(4):\n",
    "    update_gp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the new safe set\n",
    "lyapunov.update_safe_set(accuracy=accuracy)\n",
    "plot_lyapunov_1d(lyapunov, true_dynamics, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue to sample like this, until we find the maximum safe set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    update_gp()\n",
    "\n",
    "lyapunov.update_safe_set(accuracy=accuracy)\n",
    "plot_lyapunov_1d(lyapunov, true_dynamics, legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
