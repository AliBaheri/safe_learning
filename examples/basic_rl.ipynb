{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy\n",
    "%matplotlib inline\n",
    "\n",
    "# Try to import safe_rl from system\n",
    "# if it fails get it from the main folder directly instead.\n",
    "try:\n",
    "    import safe_rl\n",
    "except ImportError:\n",
    "    import utilities\n",
    "    safe_rl = utilities.import_from_directory('safe_rl', '../')\n",
    "    \n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    tqdm = lambda x: x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get matrix for values of test points\n",
    "\n",
    "For each vertex x, the next state is given by some function $f(x)$. The goal is to find the value $V(f(x))$ as a function of the values at the other vertices. This value can then be used as a constraint in the optimization problem.\n",
    "$$V(f(x)) = a^\\mathrm{T} V(\\mathrm{vertices})$$\n",
    "\n",
    "We start by finding the simplex corresponding to $f(x)$. Given this simplex's vertices, we solve for $a$ above, using one arbitrary vertex as a reference point:\n",
    "$$V(f(x)) = V(v_1) + a_1 V(v_2) + a_2 V(v_3)$$\n",
    "\n",
    "The hyperplane spanned by the simplex is given by\n",
    "\\begin{align*}\n",
    "\\xi_1 ( x_2 - x_1) + \\xi_2 (y_2 - y_1) = V(v_2) - V(v_1) \\\\\n",
    "\\xi_1 ( x_3 - x_1) + \\xi_2 (y_3 - y_1) = V(v_3) - V(v_1) \n",
    "\\end{align*}\n",
    "\n",
    "and, as a result,\n",
    "$$V(f(x_t)) = V(v_1) + (x_t - x_1, y_t - y_1)\n",
    "\\left( \\begin{matrix}\n",
    "x_2 - x_1 & y_2 - y_1 \\\\\n",
    "x_3 - x_1 & y_3 - y_1\n",
    "\\end{matrix} \\right)^{-1}\n",
    "\\left( \\begin{matrix}\n",
    "V(v_2) - V(v_1) \\\\\n",
    "V(v_3) - V(v_1)\n",
    "\\end{matrix} \\right),\n",
    "$$\n",
    "which can easily be solved for $a_1$ and $a_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Handle different terminal states in a better way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dynamics(states, actions):\n",
    "    \"\"\"Return future states of the car\"\"\"\n",
    "    states = np.atleast_2d(states)\n",
    "    actions = np.atleast_2d(actions)\n",
    "    future_states = states.copy()\n",
    "    future_states[:, 0] += states[:, 1]\n",
    "    future_states[:, 1] += 0.001 * actions[:, 0] - 0.0025 * np.cos(3 * states[:, 0])\n",
    "    \n",
    "    return future_states\n",
    "\n",
    "def reward_function(states, actions, next_states):\n",
    "    states = np.atleast_2d(states)\n",
    "    return (states[:, 0] >= 0.6).astype('int')\n",
    "\n",
    "domain = [[-1.3, 0.7], [-.08, .08]]\n",
    "n_points = [10, 10]\n",
    "delaunay = safe_rl.Delaunay(domain, n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_space = delaunay.index_to_state(np.arange(delaunay.nindex))\n",
    "action_space = np.array([-1, 1])\n",
    "\n",
    "# random initial policy\n",
    "policy = np.random.rand(len(state_space)) > 0.5\n",
    "gamma = 1 - 1e-10\n",
    "\n",
    "\n",
    "def is_terminal(states):\n",
    "    return states[:, 0] >= 0.6\n",
    "\n",
    "def is_in_domain(states, domain, eps=1e-2):\n",
    "    constraint = np.ones(len(states), dtype=np.bool)\n",
    "    for dimension, bound in zip(states.T, domain):\n",
    "        constraint &= np.logical_and(bound[0] + eps < dimension, dimension < bound[1] - eps)\n",
    "    return constraint\n",
    "\n",
    "def get_value_function(states, actions, vertex_values):\n",
    "    next_states = dynamics(states, actions)\n",
    "    rewards = reward_function(states, actions, next_states)\n",
    "    \n",
    "    legal_index = is_in_domain(next_states, domain)\n",
    "    expected_values = delaunay.function_values_at(next_states[legal_index],\n",
    "                                                  vertex_values=vertex_values)\n",
    "    values = np.zeros_like(vertex_values)\n",
    "    values[legal_index] = rewards[legal_index] + gamma * expected_values\n",
    "    values[is_terminal(states)] = 1\n",
    "    \n",
    "    return values\n",
    "    \n",
    "def optimize_policy(states, vertex_values):\n",
    "    values = np.zeros((len(vertex_values), len(action_space)), dtype=np.float)\n",
    "    actions = np.ones((delaunay.nindex, 1), dtype=np.float)\n",
    "    for i, action in enumerate(action_space):\n",
    "        actions[:] = action\n",
    "        values[:, i] = get_value_function(states, actions, vertex_values)\n",
    "        \n",
    "    best_actions = np.argmax(values, axis=1)\n",
    "    best_actions[is_terminal(states)] = 1\n",
    "    return action_space[best_actions]\n",
    "\n",
    "def value_iteration(policy, values):\n",
    "    \n",
    "    values = get_value_function(state_space, policy, values)\n",
    "    policy = optimize_policy(state_space, values)\n",
    "    return policy, values\n",
    "    \n",
    "# def optimize_value_function(states, actions, vertex_values):\n",
    "#     next_states = dynamics(states, actions)\n",
    "#     rewards = reward_function(states, actions, next_states)\n",
    "#     gamma = 0.9\n",
    "    \n",
    "#     a, b = next_states[:, 0], next_states[:, 1]\n",
    "#     legal_id = (a > domain[0][0]) & (a < domain[0][1]) & (b > domain[1][0]) & (b < domain[1][1])\n",
    "#     terminal_id = is_terminal(states)\n",
    "#     legal_id = np.logical_and(legal_id, ~terminal_id)\n",
    "#     outside_id = np.logical_and(~legal_id, ~terminal_id)\n",
    "    \n",
    "    \n",
    "#     values = cvxpy.Variable(delaunay.nindex)\n",
    "#     gamma = cvxpy.Parameter(sign='positive')\n",
    "    \n",
    "#     h = delaunay.function_values_at(next_states[legal_id]).toarray()\n",
    "    \n",
    "#     constant = np.sum(h[:, terminal_id], axis=1)\n",
    "#     expected_values = constant + h[:, legal_id] * values[legal_id]\n",
    "\n",
    "#     objective = cvxpy.Maximize(cvxpy.sum_entries(values))\n",
    "#     constraints = [values[legal_id] <= rewards[legal_id] + gamma * expected_values,\n",
    "#                    values[terminal_id] == 1,\n",
    "#                    values[outside_id] == 0]\n",
    "\n",
    "    \n",
    "#     prob = cvxpy.Problem(objective, constraints)\n",
    "#     gamma.value = 0.98\n",
    "#     prob.solve()\n",
    "    \n",
    "#     if not prob.status == cvxpy.OPTIMAL:\n",
    "#         raise ValueError('Optimization problem is {}'.format(prob.status))\n",
    "    \n",
    "#     return np.asarray(values.value).squeeze()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values = np.zeros(delaunay.nindex)\n",
    "policy = np.zeros_like(policy)\n",
    "\n",
    "old_values = values.copy()\n",
    "old_policy = policy.copy()\n",
    "\n",
    "converged = False\n",
    "\n",
    "for i in tqdm(range(1000)):\n",
    "    policy, values = value_iteration(policy, values)\n",
    "    \n",
    "    value_change = np.max(np.abs(old_values - values))\n",
    "    policy_converged = np.all(old_policy == policy)\n",
    "    if value_change <= 1e-4: # and policy_converged:\n",
    "        converged = True\n",
    "        break\n",
    "    else:\n",
    "        old_values[:] = values\n",
    "        old_policy[:] = policy\n",
    "\n",
    "if converged:\n",
    "    print('converged after {} iterations'.format(i + 1))\n",
    "else:\n",
    "    print('didnt converge, error: {} and policy: {}'.format(value_change, policy_converged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vals = values.reshape(n_points[0] + 1, n_points[1] + 1).T[::-1]\n",
    "\n",
    "ax = plt.imshow(vals, origin='upper',\n",
    "                extent=domain[0] + domain[1],\n",
    "                aspect='auto', cmap='viridis')\n",
    "plt.colorbar(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acts = policy.reshape(n_points[0] + 1, n_points[1] + 1).T[::-1]\n",
    "ax = plt.imshow(acts, origin='upper', extent=domain[0] + domain[1], aspect='auto')\n",
    "plt.colorbar(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states = np.zeros((1000, 2), dtype=np.float)\n",
    "states[0, 0] = -0.5\n",
    "\n",
    "for i in range(len(states) - 1):\n",
    "    # interpolate action\n",
    "    action = delaunay.function_values_at(states[[i], :], vertex_values=policy)\n",
    "    action = action_space[np.argmin(np.abs(action - action_space))]\n",
    "\n",
    "    states[i+1, :] = dynamics(states[i, :], action)\n",
    "    if states[i+1, 0] >= 0.6:\n",
    "        states[i+1:, :] = states[i+1]\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(states[:,0], states[:, 1])\n",
    "plt.xlabel('pos')\n",
    "plt.ylabel('vel')\n",
    "plt.xlim(-1.2, 0.6)\n",
    "plt.ylim(-0.07, 0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
