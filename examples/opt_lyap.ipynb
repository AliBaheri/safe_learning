{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import GPy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "%matplotlib inline\n",
    "\n",
    "# Try to import safe_rl from system\n",
    "# if it fails get it from the main folder directly instead.\n",
    "import utilities\n",
    "from plotting import plot_lyapunov_1d\n",
    "\n",
    "# If library not installed, import it from '../'\n",
    "safe_learning = utilities.import_from_directory('safe_learning', '../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining a discretization of the space $[-1, 1]$ with discretization constant $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Discretization constant\n",
    "tau = 0.001\n",
    "\n",
    "# x_min, x_max, discretization\n",
    "grid_param = [-1., 1., tau]\n",
    "extent = np.array(grid_param[:2])\n",
    "\n",
    "# Create a grid\n",
    "grid = np.arange(*grid_param)[:, None]\n",
    "num_samples = len(grid)\n",
    "\n",
    "print('Grid size: {0}'.format(len(grid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw system dynamics from a GP\n",
    "\n",
    "We define a kernel, $k(x,x') = k_{\\mathrm{linear}}(x, x') * k_{\\mathrm{Matern}}(x, x')$, which models a nonlinear, 2-times differentiable function with linearly increasing amplitude. We draw a sample from this kernel in order to define the dynamics.\n",
    "\n",
    "The following plot shows the kind of functions that this kernel implies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kernel = GPy.kern.Matern32(1, lengthscale=0.2, variance=0.2**2) * GPy.kern.Linear(1)\n",
    "\n",
    "for i in range(10):\n",
    "    f = safe_learning.utilities.sample_gp_function(\n",
    "        kernel,\n",
    "        [extent],\n",
    "        num_samples=100,\n",
    "        noise_var=0.1,\n",
    "        interpolation='kernel')\n",
    "    plt.plot(grid, f(grid, noise=False))\n",
    "\n",
    "plt.ylabel('$g(x)$')\n",
    "plt.xlabel('x')\n",
    "plt.title('Samples drawn from the GP model of the dynamics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the GP model using one particular sample of the GP, in addition to a stable, closed-loop, linear model.\n",
    "$$x_{l+1} = 0.25 x_k + g_\\pi(x),$$\n",
    "\n",
    "The prior dynamics are locally asymptotically stable. Moreover, in the one-dimensional case, the dynamics are stable as long as $|x_{k+1}| \\leq |x_{k}|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Observation noise\n",
    "noise_var = 0.01 ** 2\n",
    "\n",
    "# Mean dynamics\n",
    "mf = GPy.core.Mapping(1, 1)\n",
    "mf.f = lambda x: 0.25 * x\n",
    "mf.update_gradients = lambda a, b: None\n",
    "\n",
    "# Define one sample as the true dynamics\n",
    "np.random.seed(5)\n",
    "true_dynamics = safe_learning.utilities.sample_gp_function(\n",
    "    kernel,\n",
    "    [extent],\n",
    "    num_samples=100,\n",
    "    noise_var=noise_var,\n",
    "    interpolation='kernel',\n",
    "    mean_function=mf.f)\n",
    "\n",
    "# Define a GP model over the dynamics\n",
    "gp = GPy.models.GPRegression(np.array([[0]]),\n",
    "                             np.array([[0]]),\n",
    "                             kernel,\n",
    "                             noise_var=noise_var,\n",
    "                             mean_function=mf)\n",
    "\n",
    "# Plot the basic model\n",
    "gp.plot_f(plot_limits=extent)\n",
    "plt.plot(grid, true_dynamics(grid, noise=False), color='black', alpha=0.8)\n",
    "plt.title('GP model of the dynamics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally we define a random lyapunov function. Unlike for multiple dimensions, in the one-dimensional case all radially increasing functions are equivalent. Here we pick\n",
    "$$V(x) = x^2$$\n",
    "The previous GP model defines a GP model over $\\dot{V}(x) = \\frac{\\partial V(x)}{\\partial x} f(x)$. In the following, we only consider the 2-$\\sigma$ upper confidence bound of this model. Since the dynamics are Lipschitz continuous, $\\dot{V}$ is Lipschitz continuous as well.\n",
    "\n",
    "In particular, we use Lemma 5 to determine an appropriate Lipschitz constant. For the sample path of the GP, we use the high-probability Lipschitz constant encoded by the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lyapunov_function = safe_learning.QuadraticFunction(np.array([[1]]))\n",
    "# n_linear = 10\n",
    "# lyapunov_function = safe_learning.Triangulation(extent[None, :], n_linear)\n",
    "# points = lyapunov_function.index_to_state(np.arange(lyapunov_function.nindex))\n",
    "# lyapunov_function.vertex_values = points.squeeze() ** 2\n",
    "lyapunov_function = safe_learning.Triangulation(extent[None, :], 100)\n",
    "lyapunov_function.vertex_values = lyapunov_function.index_to_state(np.arange(lyapunov_function.nindex)).squeeze() ** 2\n",
    "\n",
    "dynamics = safe_learning.UncertainFunction.from_gpy(gp, beta=2.)\n",
    "\n",
    "# Lipschitz constant\n",
    "L_dyn = 0.25 + dynamics.beta(0) * np.sqrt(gp.kern.Mat32.variance) / gp.kern.Mat32.lengthscale * np.max(np.abs(extent))\n",
    "L_V = np.max(lyapunov_function.gradient(grid))\n",
    "\n",
    "lyapunov = safe_learning.LyapunovDiscrete(grid, lyapunov_function, dynamics, L_dyn, L_V, tau, initial_set=None)\n",
    "\n",
    "# Specify the desired accuracy\n",
    "accuracy = np.max(lyapunov.V) / 1e10\n",
    "\n",
    "lyapunov.initial_safe_set = np.abs(lyapunov.discretization.squeeze()) < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# min x_i \n",
    "# x_i >= 0\n",
    "# l_v = max gradient\n",
    "# for all discrete points:\n",
    "#     V(mu_x) - V(x) + l_v * v_dot_error + l_v (1 + l_f) eps <= xi_i\n",
    "import cvxpy\n",
    "\n",
    "discretization = lyapunov_function.index_to_state(np.arange(lyapunov_function.nindex))\n",
    "dynamics_mean, dynamics_error = dynamics.evaluate(discretization)\n",
    "\n",
    "values = cvxpy.Variable(len(discretization))\n",
    "slack = cvxpy.Variable(len(discretization))\n",
    "\n",
    "# Get the gradients at each triangle.\n",
    "simplex_indeces = np.arange(lyapunov_function.nsimplex)\n",
    "gradient_mat = lyapunov_function.gradient_constraint(simplex_indeces, index=True)\n",
    "gradient_mat = cvxpy.Constant(gradient_mat)\n",
    "\n",
    "gradients = gradient_mat * values\n",
    "l_v = cvxpy.max_entries(cvxpy.abs(gradients))\n",
    "\n",
    "constraints = []\n",
    "constraints.append(slack >= 0)\n",
    "\n",
    "\n",
    "# next_states = self.dynamics(self.state_space, self.policy)\n",
    "# rewards = self.reward_function(self.state_space,\n",
    "#                                self.policy,\n",
    "#                                next_states)\n",
    "# rewards[self.terminal_states] = self.terminal_reward\n",
    "\n",
    "# # Define random variables\n",
    "# values = cvxpy.Variable(self.value_function.nindex)\n",
    "# objective = cvxpy.Maximize(cvxpy.sum_entries(values))\n",
    "\n",
    "# value_matrix = self.value_function.evaluate_constraint(next_states)\n",
    "# # Make cvxpy work with sparse matrices\n",
    "# value_matrix = cvxpy.Constant(value_matrix)\n",
    "\n",
    "# future_values = rewards + self.gamma * value_matrix * values\n",
    "\n",
    "# constraints = [values <= future_values,\n",
    "#                values[self.terminal_states] == self.terminal_reward]\n",
    "\n",
    "# prob = cvxpy.Problem(objective, constraints)\n",
    "# prob.solve()\n",
    "\n",
    "# if not prob.status == cvxpy.OPTIMAL:\n",
    "#     raise ValueError('Optimization problem is {}'.format(prob.status))\n",
    "\n",
    "# self.value_function.vertex_values[:] = values.value.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyapunov.update_safe_set(accuracy=accuracy)\n",
    "plot_lyapunov_1d(lyapunov, true_dynamics, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
